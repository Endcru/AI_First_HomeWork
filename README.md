# **Домашнее задание №1 (base).**

### Константинов Никита

## Проделанная работа

Первой частью выполнения домашнего задания стало проведение EDA по полученным для обучения моделей данных. В первую очередь было установлено наличие дублей и пропусков в данных. Дубли были удалены, а пропуски заполнены медианами.

Второй важной проблемой в данных стало то, что признаки ``mileage, engine, max_power и torque`` представляли из себя строки, хоть и являлись на самом деле вещественными признаками, а потому они были переведены в float с удалением лишних частей (как например обозначение единиц измерения). Так же к int были приведены ``seats и engine``.

Были проведён анализ статистики по train и test в результате чего сделаны следующие выводы:

1. В train и test примерно одинаковые средние значения данных, это говорит нам о том, что данные были хорошо разделдены на train и test.
2. В признаке year нет больших значений отличающихся от среднего

3. В selling_price можно увидеть, что стандартное отклонение больше чем среднее значение, а значит у данных большой запрос, а так же много значений с большим перевесом в сторону большой цены

4. По признаку km_driven можно сказать что у данныхъ так же большой разброс среднее отклонение почти достигает среднего.

5. В признаке mileage особо нечего отметить, обычное распределение значений

6. В признаке engine особо нечего отметить, обычное распределение значений

7. В признаке max_power особо нечего отметить, обычное распределение значений

8. Большиснвто машин имеют 5 сидений

9. Категориальные признаки что в train что в test имеют одинаковое количество уникальных значений, за исключением признака name. Это говорит нам о том, что в данных для обучения мы используем все категории, которые потом встретятся в тесте, что позволит лучше обучить модель. Что касается признака name то у него слишком много уникальных значений, так что веротяно его стоит удалить.

Далее была проведена визуализация данных. Были построины графики попарного распределения числовых признаков. В итоге на основе графиков сделаны следующие выводы по кореляции с целевой переменной:

1. year - Возможна положительная кореляция - можно провести линию

2. mileage - Нет кореляции, все данные практически стоят одним столбцом

3. seats - Нет кореляции

Для подтверждения кореляци была построена корреляция Пирсона и тепловая карта для неё. В результате сделаны следующие выводы:

1. Наибольшую кореляцию имеют max_power и selling_price в 0.692725

2. Наименьшую кореляцию имеют km_driven и max_power в 0.024

3. Сильная положительная зависимость наблюдается между engine-seats, engine-max_power, selling_price-max_power и сравнительно меньшьая но достаточная между selling_price-year и selling_price-engine

Следующим этапом стало обучение моделей на вещественных признаков. Для удобства результаты всех моделей будут собраны ниже пред выводом. Для оценки качества моделей использовались метрики $R^2$ и $MSE$. 

Первой была обучена Линейная регрессия на необработанных данных. итоговый резулоьтат получился сравнительно неплохим, но далеко не идельным, а следовательно было необходимо улучшать. 

Далее для улучшения было принято решение стандартизировать признаки с помощью StandardScaler. итоговый результат практически не изменился, показав улучшенные метрики 

Далее была применена Lasso регрессия для регуляризации. Однако никакие веса не были занулены, а метрики не только не увеличились, а наоборот слегка упали, однако это произошло в пределах погрешности. 

Далее было решено подобрать оптимальные парметры для Lasso регрессии с помощью Gridsearch. Удалось занулить параметр seats, однако метрики наоборот лишь ухудшились несмотря на подбор. 

То же самое можно сказать и про использование ElasticNet, показавшей в итоге наихудший результат, однако даже он не отличался от изначального больше чем на 0.01 по r2_score. 

Наилучшего же рузультата удалось добиться добавив категориальные фичи, где был убран столбец ``name`` и преоьбразованы столбцы ``seats, fuel, seller_type, transmission и owner`` с помощью OneHotEncoder. Также стандартизировались признаки с помощью StandardScaler. использовалась гребневая регрессия с Gridsearch по параметру alpha. 

Дополниельно была составлена бизнесовая мтерика: Долю прогнозов, отличающихся от реальных цен на эти авто не более чем на 10%

Далее представлены результаты работы моделей

### Модель Классическая линейная регрессия без стандартизации
r2_score train / test: 0.5915050767325436 / 0.5937024338674333
MSE train / test: 117090306033.0161 / 233551443099.39868
Бизнес метрика train: 0.21523972602739727 / 0.225

### Модель Классическая линейная регрессия со стандартизацией
r2_score train / test: 0.591505076732544 / 0.5937024338674468
MSE train / test: 117090306033.01596 / 233551443099.39087
Бизнес метрика train: 0.21523972602739727 / 0.225

### Модель Lasso регрессия
r2_score train / test: 0.5915050766972044 / 0.5937012618474564
MSE train / test: 117090306043.14563 / 233552116809.94913
Бизнес метрика train: 0.21523972602739727 / 0.225

### Модель Lasso регрессия с Greedsearch
r2_score train / test: 0.5885508836739031 / 0.5812248664645336
MSE train / test: 117937091022.5332 / 240723905147.48877
Бизнес метрика train: 0.2089041095890411 / 0.236

### Модель ElasticNet регрессия с Greedsearch
r2_score train / test: 0.583801282286214 / 0.5610639679012236
MSE train / test: 119298508872.16272 / 252312965349.0095
Бизнес метрика train: 0.22226027397260273 / 0.247

### Модель Ridge с категориальными признаками c Greedsearch
r2_score train / test: 0.6573210327247365 / 0.6025619385720483
MSE train / test: 98224929769.97812 / 228458746806.3728
Бизнес метрика train: 0.22773972602739725 / 0.269

В результате выходит что для залач бизнеса лучше всего подходят Модель Ridge с категориальными признаками c Greedsearch. таким образом можно точно сказать что добавление категориальных признаков дало наибольший рост качества модели.

Также получается интресное положение: несмотря на то что r2_score часто уменьшалась на тетсовых данных, а на модель Ridge лишь незначительно увеличилась по сравнению с Классической регрессией. Бизнес метрика постоянно росла во время улучшения наших моделей. Таким образом с точки зрения реальной задачи все шаги проделанные были верны.

Последним этапом стало создание Streamlit приложения. Оно было разработано с использованием pickle файлов полученных из `.ipynb`-ноутбук при обучении модели. Приложение выводит все полученные талицы в графики в EDA, а также график весов обученной модели (сами веса не выводятся во избежании их точного копирования при открытия приложения). Приложение также способно предлсказывать цены машины на основе лучшей из получившихся моделей. Полученный результат можно увидеть в таблице в приложении и скачать также в csv файле.

Ссылка на прилодение Streamlit: https://ai-first-homework-nd-konst.streamlit.app/

## Что не удалось сделать 

Не удалось получить подобрать оптимальные парметры для Lasso регрессии с помощью Gridsearch и для ElasticNet. несмотря на все выбранные парметры метрики всё равно падали. Вероятно был способ всё же сделать это лучше. 

## Оценка разработанного сервиса

Приложение удобно для использования ибо скрывает лишние графики для тех, кто не хочет на них смотреть. Едлинственное неудобство это то что графики рисуются каждый раз коргда приложение презагружается. Была мысль сохранить ихз  в виде картинок и загружать автоматически, однако из-за этого в случае если приложением пользоваться далее и менять train данные, то могут остаться старые картинки. В результате было принято решение что отрисовка графиков сравнительно быстрая и можно это сотавить, просто добавив надпись Подождите, данные обрабатываются... пока графики рисуются. 

Так же визуализация 'Попарное распределение числовых признаков на train' немного неудавчное так как имеет слишком разных маштаб на разных признаков, из-за чего некоторые графики почти нечитаемы. Оданко кдалось сделать  целом весь набор читаемым разместив его на половине экрана и подобрав параметры с которыми он не мыльный. 